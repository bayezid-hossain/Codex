# ğŸ§  Codex Annotation Task

## ğŸ“Œ Overview

This repository supports the **Codex** project, which focuses on evaluating the capabilities of two different Codex-based language models.

## ğŸ¤– Models Involved

- ğŸ§ª **`codex-experimental` model**  
- ğŸ **`codex-production` model**

## ğŸ“ Task Description

Annotators are presented with prompts alongside responses from the two Codex models. The goal is to **compare and evaluate** the responses across several dimensions:

- âœ… **Relevance** â€“ Does the response address the intent of the prompt?
- ğŸ§  **Clarity** â€“ Is the response well-structured and easy to understand?
- ğŸ¯ **Accuracy** â€“ Are the facts or code correct and appropriate?
- ğŸ™Œ **Helpfulness** â€“ Does the response effectively solve the problem or answer the question?

The feedback from these annotations informs model improvements and helps prioritize updates to the **Codex production model**.
