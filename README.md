# 🧠 Codex Annotation Task

## 📌 Overview

This repository supports the **Codex** project, which focuses on evaluating the capabilities of two different Codex-based language models.

## 🤖 Models Involved

- 🧪 **`codex-experimental` model**  
- 🏁 **`codex-production` model**

## 📝 Task Description

Annotators are presented with prompts alongside responses from the two Codex models. The goal is to **compare and evaluate** the responses across several dimensions:

- ✅ **Relevance** – Does the response address the intent of the prompt?
- 🧠 **Clarity** – Is the response well-structured and easy to understand?
- 🎯 **Accuracy** – Are the facts or code correct and appropriate?
- 🙌 **Helpfulness** – Does the response effectively solve the problem or answer the question?

The feedback from these annotations informs model improvements and helps prioritize updates to the **Codex production model**.
